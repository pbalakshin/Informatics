\section{Сжатие данных}
\label{sec:data_compression}

\textit{\textbf{Сжатие данных} --- это процесс, обеспечивающий уменьшение объема данных путем сокращения их избыточности.}

\rightline{К. Шеннон}

\bigskip

Клода Шеннона принято считать основоположником науки о сжатии информации. Его теорема об оптимальном кодировании показывает, к чему нужно стремиться при кодировании информации и насколько та или иная информация при этом сожмется. Кроме того, им были проведены опыты по эмпирической оценке избыточности английского текста. Шенон предлагал людям угадывать следующую букву и оценивал вероятность правильного угадывания. На основе ряда опытов он пришел к выводу, что количество информации в английском тексте колеблется в пределах 0,6 – 1,3 бита на символ. Несмотря на то, что результаты исследований Шеннона были по-настоящему востребованы лишь десятилетия спустя, трудно переоценить их значение.

\bigskip

\emph{Сжатие данных} --- это частный случай \emph{кодирования} данных и важнейший аспект передачи данных, что дает возможность более оперативно передавать данные. 

\bigskip

\emph{Цель сжатия} --- уменьшение количества бит, необходимых для хранения или передачи заданной информации, что дает возможность передавать сообщения более быстро и хранить более экономно и оперативно (последнее означает, что операция извлечения данной информации с устройства ее хранения будет проходить быстрее, что возможно, если скорость распаковки данных выше скорости считывания данных с носителя информации).

\bigskip

Сжатие позволяет, например, записать больше информации на дискету, ``увеличить'' размер жесткого диска, ускорить работу с модемом и т.д. При работе с компьютерами широко используются программы-архиваторы данных формата ZIP, GZ, ARJ и других. Методы сжатия информации были разработаны как математическая теория, которая долгое время (до первой половины 80-х годов), мало использовалась в компьютерах на практике.

\bigskip

\noindentВведем ряд определений, которые будут использоваться далее в изложении материала.
\begin{description}
    \item [Алгоритм сжатия данных (алгоритм архивации)] --- это алгоритм, который устраняет избыточность записи данных.
    \item [Символ] --- наименьшая единица данных, рассматриваемая как единое целое при кодировании/декодировании.
    \item [Алфавит] --- множество всех возможных символов.
    При сжатии англоязычных текстов обычно используют множество из 128 ASCII кодов.
    При сжатии изображений множество значений пиксела может содержать 2, 16, 256 или другое количество элементов.
\end{description}

\bigskip

Рассмотрим на примере. Возьмем обычную книгу и будем считать ее содержимое как за исходные данные.
За символ мы можем взять как букву (и тогда алфавитом будет являться обычный алфавит русского языка), так и целое слово (тогда алфавит будет состоять из всех уникальных слов, встречающихся в этой книге).
Символ - не обязательно один знак.
Символом могут являться слова и даже целые предложения.

\begin{description}
    \item [Токен] --- единица данных, записываемая в сжатый поток некоторым алгоритмом сжатия.
    Токен состоит из нескольких полей фиксированной или переменной длины.
    \item [Фраза] --- фрагмент данных, помещаемый в словарь для дальнейшего использования в сжатии.
    \item [Код] --- правило соответствия набора знаков одного множества $X$ знакам другого множества $Y$.
    \item [Кодирование] --- процесс преобразования символов алфавита $X$ в символы алфавита $Y$.
    \item [Декодирование] --- процесс, обратный кодированию, при котором осуществляется восстановление данных.
    \item[Кодовый символ] --- наименьшая единица данных, подлежащая сжатию. Обычно символ --- это 1 байт, но он может быть битом, тритом {0,1,2}, или чем-либо еще.
    \item[Кодовое слово] --- это последовательность кодовых символов из алфавита кода.
    \item [Средняя длина кодового слова] --- это величина, которая вычисляется как взвешенная вероятностями сумма длин всех кодовых слов. \\ То есть:
    $$ L = \sum_{i=1}^{N}p_{i} \times l_{i} $$
    где:
    \begin{description}[noitemsep]
        \item [$N$] --- количество кодовых слов в алфавите;
        \item [$p_{i}$] --- вероятность появления кодового слова в последовательности;
        \item [$l_{i}$] --- количество символов в кодовом слове (длина кодового слова).
    \end{description}
    Сумма всех $p_{i}$ должна быть равна единице.
\end{description}

Если все кодовые слова имеют одинаковую длину, то код называется \textbf{равномерным} (фиксированной длины).
Если встречаются слова разной длины, то --- \textbf{неравномерным} (переменной длины)

Классический пример равномерного кода --- таблица символов ASCII.
Любой символ из этой таблицы будет закодирован одним байтом (один символ всегда кодируется двумя цифрами в шестнадцатеричной системе счисления).
Пример неравномерного кода --- азбука Морзе.

\paragraph{Характеристики кодирования}

\begin{equation*}
\mbox{Коэффициент сжатия} = \frac{\mbox{Размер входного потока}}{\mbox{Размер выходного потока}}
\end{equation*}

\noindentЗначения больше 1 обозначают сжатие, а значения меньше 1 --- расширение.

\begin{equation*}
\mbox{Отношение сжатия} = \frac{\mbox{Размер выходного потока}}{\mbox{Размер входного потока}}    
\end{equation*}

\noindentЗначение $0,6$ означает, что данные занимают $60\%$ от первоначального объема.
Значения больше 1 означают, что выходной поток больше входного (отрицательное сжатие, или расширение).

\bigskip

\paragraph{Сжатие данных можно разделить на два основных типа:}

\begin{description}
    \item [Сжатие без потерь (\emph{полностью обратимое})] --- это метод сжатия данных, при котором ранее закодированная порция данных восстанавливается после их распаковки полностью без внесения изменений.
    Для каждого типа данных, как правило, существуют свои оптимальные алгоритмы сжатия без потерь.
    \item [Сжатие с потерями (\emph{частично обратимое})] --- это метод сжатия данных, при котором для обеспечения максимальной степени сжатия исходного массива данных часть содержащихся в нем данных отбрасывается.
    Для текстовых, числовых и табличных данных использование программ, реализующих подобные методы сжатия, является неприемлемыми.
    В основном такие алгоритмы применяются для сжатия аудио- и видеоданных, статических изображений.
\end{description}

\paragraph{Существуют два основных способа проведения сжатия:}

\begin{description}
    \item [Статические методы] --- методы сжатия, присваивающие коды переменной длины символам входного потока, причем более короткие коды присваиваются символам или группам символам, имеющим большую вероятность появления во входном потоке.
    Лучшие статистические методы применяют кодирование Хаффмана.
    \item [Словарное сжатие] --- это методы сжатия, хранящие фрагменты данных в "словаре" (некоторая структура данных).
    Если строка новых данных, поступающих на вход, идентична какому-либо фрагменту, уже находящемуся в словаре, в выходной поток помещается указатель на этот фрагмент. 
\end{description}

\paragraph{Основные понятия кодирования:}

\subparagraph{Префиксный код} --- это код, в котором никакое кодовое слово не является префиксом любого другого кодового слова. Эти коды имеют переменную длину.

\subparagraph{Оптимальный префиксный код} --- это префиксный код, имеющий минимальную среднюю длину.

\subsection{Алгоритмы сжатия данных}
\label{subsec:data_compression_algorithms}

\input{src/05_data_compression/01_shannon_fano}
\input{src/05_data_compression/02_huffman}